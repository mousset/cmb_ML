{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= int(time.time())#20#0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camb\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv1D, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from create_training_data_clean import *\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for the healpix map\n",
    "nside = 16\n",
    "npix = 12 * nside ** 2\n",
    "nl = 2 * nside\n",
    "lmax = nl - 1\n",
    "nalm = int(nl * (nl + 1) / 2)\n",
    "\n",
    "# Number of Training models\n",
    "nbmodels = 200000\n",
    "\n",
    "#White Noise\n",
    "noise_rms = 200\n",
    "noisy_bool = noise_rms != 0\n",
    "\n",
    "new_lmin = 2\n",
    "if noisy_bool:\n",
    "    new_lmax = lmax\n",
    "else:\n",
    "    new_lmax = lmax-1\n",
    "\n",
    "nl_used = nl - ((new_lmin + (lmax-new_lmax)))\n",
    "\n",
    "#Selecting spectrum\n",
    "spectrum = \"BB\"\n",
    "clnames = ['TT', 'EE', 'BB', 'TE']\n",
    "idx_cell = clnames.index(spectrum)\n",
    "\n",
    "#Data path\n",
    "path_dir_data = \"data_FullSky\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_file_{}_10000\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 5000\n",
    "n_epochs = 400#30#400\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Architecture\n",
    "dropout_val = 0.5\n",
    "n_hidden_layer = 2\n",
    "\n",
    "#Training\n",
    "training_fraction = 0.8\n",
    "mult_fact = 1e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path + \"_{}_layer\".format(n_hidden_layer)\n",
    "if n_hidden_layer > 1:\n",
    "    path = path + \"s\"\n",
    "if dropout_val > 0:\n",
    "    path = path + \"_dropout\"\n",
    "if noisy_bool:\n",
    "    path = path + \"_noise\"\n",
    "\n",
    "path = path + \"_{}_{}_{}_epochs_{}_out_x{}\".format(lmin, new_lmax, n_epochs, spectrum, mult_fact)\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating/Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating input spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "cl_ana, alm_ana = CreateAnafastFullSky(cl_camb, nside, lmax, nl)\n",
    "ll = np.arange(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data and stores it into files\n",
    "if not os.path.isfile(data_filename):\n",
    "    for i in range(nbmodels//10000):\n",
    "        all_cl_theo, all_alm_ana, all_cl_ana = CreateModelsSmoothSpectra(10000, nl, npix, nalm, nside, lmin, lmax, cl_camb, noise_rms = noise_rms, plot_some_spectra=False)\n",
    "        \n",
    "        #\"\"\"\n",
    "        if not os.path.isdir(path_dir_data):\n",
    "            os.mkdir(path_dir_data)\n",
    "        data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "        data_file = open(data_filename, \"wb\")\n",
    "        pickle.dump([all_cl_theo, all_alm_ana, all_cl_ana], data_file)\n",
    "        data_file.close()\n",
    "        #\"\"\"\n",
    "\n",
    "# load generated data\n",
    "all_cl_theo, all_alm_ana, all_cl_ana = np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    [all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans = all_cl_theo_trans[idx_cell], all_alm_ana_trans[idx_cell], all_cl_ana_trans[idx_cell]\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        exit()\n",
    "        all_cl_theo_trans, all_alm_ana_trans, all_cl_ana_trans = all_cl_theo_trans[idx_cell], all_alm_ana_trans[0], all_cl_ana_trans[idx_cell]\n",
    "    if i == 0:\n",
    "        all_cl_theo = all_cl_theo_trans.copy()\n",
    "        print(all_cl_theo.shape)\n",
    "        all_cl_theo_trans = []\n",
    "        all_alm_ana = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_ana = all_cl_ana_trans.copy()\n",
    "        all_cl_ana_trans = []\n",
    "    else:\n",
    "        all_cl_theo = np.append(all_cl_theo, all_cl_theo_trans, axis=0)\n",
    "        all_cl_theo_trans = []\n",
    "        all_alm_ana = np.append(all_alm_ana, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_ana = np.append(all_cl_ana, all_cl_ana_trans, axis=0)\n",
    "        all_cl_ana_trans = []\n",
    "    data_file.close()\n",
    "    if all_cl_theo.shape[0] >= nbmodels:\n",
    "        break\n",
    "\n",
    "print(all_cl_theo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl_noise = np.zeros(all_cl_theo.shape) + noise_rms**2*4*np.pi/npix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting $\\ell$ range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cl_theo = all_cl_theo[:, new_lmin:new_lmax+1]\n",
    "all_cl_noise = all_cl_noise[:, new_lmin:new_lmax+1]\n",
    "all_cl_ana = all_cl_ana[:, new_lmin:new_lmax+1]\n",
    "ll = ll[new_lmin:new_lmax+1]\n",
    "\n",
    "print(all_cl_theo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Inputs alm real and imaginary parts are normalised separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_alm_real = np.max(np.abs(all_alm_ana.real))\n",
    "max_alm_imag = np.max(np.abs(all_alm_ana.imag))\n",
    "all_alm_ana = np.stack((all_alm_ana.real/max_alm_real, all_alm_ana.imag/max_alm_imag), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test\n",
    "The mult_fact factor is a trick to get better performances. It changes the scale of the expected training output (y_train). \n",
    "The neural network will then predict an values of the same scale. To get back to the original scale, we then need to divide the predicted values by the mult_fact factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilim = int(all_cl_theo.shape[0] * training_fraction)\n",
    "print(ilim)\n",
    "\n",
    "x_train = all_alm_ana[0:ilim, :]\n",
    "y_train = (all_cl_theo + all_cl_noise)[0:ilim, :]*mult_fact\n",
    "\n",
    "y_test = (all_cl_theo + all_cl_noise)[ilim:, :]\n",
    "x_test = all_alm_ana[ilim:, :]\n",
    "\n",
    "\"\"\"Sample variance\"\"\"\n",
    "sample_variance = 2/(2*ll +1)*(all_cl_theo + all_cl_noise)**2\n",
    "sample_variance_train = sample_variance[0:ilim, :]*mult_fact**2\n",
    "sample_variance_test = sample_variance[ilim:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# Dealing with different keras versions\n",
    "try:\n",
    "        adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "except:\n",
    "        adam = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "Here we will use a neural network with the same number of neurons in each hidden layer.\n",
    "We also add a Conv1D layer to tell the network to treat real and imaginary parts of each alm together. \n",
    "We got two times nalm values as inputs (real and imaginary part of each alm) and nl_used values as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalm_model = nalm\n",
    "print(nalm_model)\n",
    "\n",
    "input_layer = Input(shape=(nalm,2))\n",
    "conv_layer = Conv1D(filters=1, kernel_size=2)(input_layer)\n",
    "flatten = Flatten()(conv_layer)\n",
    "hidden = Dense(units=nalm_model*6, activation='relu', kernel_initializer='uniform')(input_layer)\n",
    "\n",
    "# Adding hidden layers\n",
    "for i in range(n_hidden_layer-2):\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "    \n",
    "# Adding Dropout layer just before the last hidden layer \n",
    "if dropout_val > 0:\n",
    "    dropout = Dropout(dropout_val)(hidden)\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(dropout)\n",
    "else:\n",
    "    hidden = Dense(units=nalm_model*6, activation='relu')(hidden)\n",
    "\n",
    "output_layer = Dense(units=nl_used, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating outer model\n",
    "To use sample_variance in the loss function without giving it directly to the network, we need to create another model.\n",
    "Inspired from https://stackoverflow.com/questions/50706160/how-to-define-custom-cost-function-that-depends-on-input-when-using-imagedatagen/50707473#50707473\n",
    "\n",
    "Training this model will also train the original one.\n",
    "\n",
    "We also define are loss here in the innerLoss function: \n",
    "$$\\frac{1}{nl_{used}}\\sum_{n=0}^{nl_{used}}\\frac{(C_{\\ell,n}^{pred} - C_{\\ell,n}^{true})^2}{\\sigma_{C_{\\ell,n}}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalLoss(true,pred):\n",
    "    return pred\n",
    "\n",
    "def innerLoss(x):\n",
    "    y_pred = x[0] \n",
    "    y_true = x[1]\n",
    "    selected_sample_variance_train = x[2]\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    # full sky case: y_true = mean(y_pred) for Anafast\n",
    "    chi2_loss = K.sum(K.abs(y_pred - y_true)**2/selected_sample_variance_train, axis=-1)/nl_used\n",
    "\n",
    "    error = chi2_loss\n",
    "    return error\n",
    "\n",
    "#this model has three inputs:\n",
    "originalInputs = model.input  \n",
    "yTrueInputs = Input(shape=(nl_used,))\n",
    "sample_variance_Inputs = Input(shape=(nl_used,))\n",
    "\n",
    "#the original outputs will become an input for a custom loss layer\n",
    "originalOutputs = model.output\n",
    "\n",
    "#this layer contains our custom loss\n",
    "loss = Lambda(innerLoss)([originalOutputs, yTrueInputs, sample_variance_Inputs])\n",
    "\n",
    "#outer model\n",
    "outerModel = Model(inputs=[originalInputs, yTrueInputs, sample_variance_Inputs], outputs=loss)\n",
    "\n",
    "outerModel.compile(optimizer=adam, loss=finalLoss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load model weights\n",
    "#model.load_weights(\"models_complex_4_layers_conv_alternate_different_norm_early_stop_2000/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining EarlyStopping to restore the best network at the end of the training\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=200,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = outerModel.fit(x=[x_train, y_train, sample_variance_train],y=y_train,\n",
    "            epochs=n_epochs,\n",
    "            batch_size= batch_size,\n",
    "\t        verbose=1,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models_FullSky\"\n",
    "if noisy_bool:\n",
    "    model_dir = model_dir + \"_noise\"\n",
    "model_dir = model_dir + \"_{}\".format(spectrum) \n",
    "if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\"\"\"\n",
    "# save model and architecture to single file\n",
    "model.save(\"models/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\"\n",
    "#\"\"\"\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(model_dir + \"/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "figname = 'fig_loss.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest)  # write image to file\n",
    "plt.clf()\n",
    "\n",
    "print(min(history.history['loss']),\n",
    "      min(history.history['val_loss']),\n",
    "      len(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anafast predictions\n",
    "all_cl_ana_test = all_cl_ana[ilim:, :]\n",
    "\n",
    "# Neural Network predictions\n",
    "result = model.predict(x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "if spectrum != \"TE\":\n",
    "    result[result < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(sample_variance, Cl_true, Cl_pred):\n",
    "    # chi2\n",
    "    val = np.sum((Cl_pred-Cl_true)**2/sample_variance, axis=-1)/nl_used #sum over \\ell\n",
    "    return val\n",
    "\n",
    "metric_val_anafast = metric(sample_variance_test[: ,:], all_cl_ana_test[: ,:], y_test[: ,:])\n",
    "metric_val_ml = metric(sample_variance_test[: ,:], result[: ,:], y_test[: ,:])\n",
    "\n",
    "print(metric_val_namaster, metric_val_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "def statstr(x):\n",
    "    return '{0:8.3f} +/- {1:8.3f}'.format(np.mean(x), np.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ Anafast'.format(nl_used) + statstr(metric_val_anafast))\n",
    "plt.hist(metric_val_ml, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ ML '.format(nl_used) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_anafast, bins=10, range=[0, 2], alpha=0.5, label=r'$N_\\ell = {}$ Anafast'.format(nl_used) + statstr(metric_val_anafast))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "figname = 'fig_chi2_metric_ana.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.hist(metric_val_ml, bins=10, range=[max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml))], alpha=0.5, label=r'$N_\\ell = {}$ ML '.format(nl_used) + statstr(metric_val_ml))\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\chi^2 metric$\")\n",
    "plt.ylabel(r\"\")\n",
    "plt.title(spectrum)\n",
    "plt.xlim(max(np.mean(metric_val_ml)-np.std(metric_val_ml), 0), min(np.mean(metric_val_ml)+np.std(metric_val_ml), 1.5*np.mean(metric_val_ml)))\n",
    "figname = 'fig_chi2_metric_ml.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    plt.figure(dpi=120)\n",
    "    if noisy_bool:\n",
    "        plt.plot(ll, ll * (ll + 1) * y_test[i, :], label='Input spectra + noise')\n",
    "    else:\n",
    "        plt.plot(ll, ll * (ll + 1) * y_test[i, :], label='Input spectra')\n",
    "    plt.plot(ll, ll * (ll + 1) * all_cl_ana_test[i, :], label='Anafast')\n",
    "    plt.plot(ll, ll * (ll + 1) * result[i, :], label='ML')\n",
    "    plt.xlabel(r\"$\\ell$\")\n",
    "    text = r\"$\\ell (\\ell + 1) C_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "    plt.ylabel(text)\n",
    "    plt.title(spectrum)\n",
    "    plt.legend()\n",
    "    figname = 'fig_prediction{}.png'.format(i)\n",
    "    dest = os.path.join(path, figname)\n",
    "    plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mectrics.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"Anafast: {}\\n\".format(statstr(metric_val_anafast)))\n",
    "f.write(\"ML: {}\\n\".format(statstr(metric_val_ml)))\n",
    "f.write(\"ML min training loss: {}\\n\".format(min(history.history['loss'])))\n",
    "f.write(\"ML min validation loss: {}\\n\".format(min(history.history['val_loss'])))\n",
    "f.close()\n",
    "\n",
    "filename = \"parameters.txt\"\n",
    "dest = os.path.join(path, filename)\n",
    "f = open(dest, \"w\")\n",
    "f.write(\"batch_size: {}\\n\".format(batch_size))\n",
    "f.write(\"n_epochs: {}\\n\".format(n_epochs))\n",
    "f.write(\"learning_rate: {}\\n\".format(learning_rate))\n",
    "f.write(\"nside: {}\\n\".format(nside))\n",
    "f.write(\"npix: {}\\n\".format(npix))\n",
    "f.write(\"nl: {}\\n\".format(nl))\n",
    "f.write(\"lmax: {}\\n\".format(lmax))\n",
    "f.write(\"nalm: {}\\n\".format(nalm))\n",
    "f.write(\"n_training: {}\\n\".format(int(0.9*ilim)))\n",
    "f.write(\"n_testing: {}\\n\".format(x_test.shape[0]))\n",
    "f.write(\"nbmodels: {}\\n\".format(nbmodels))\n",
    "f.write(\"new_lmin: {}\\n\".format(new_lmin))\n",
    "f.write(\"new_lmax: {}\\n\".format(new_lmax))\n",
    "f.write(\"nl_used: {}\\n\".format(nl_used))\n",
    "f.write(\"training_fraction: {}\\n\".format(training_fraction))\n",
    "f.write(\"stopped at epoch: {}\\n\".format(len(history.history['loss'])))\n",
    "f.write(\"noise_rms: {}\\n\".format(noise_rms))\n",
    "f.write(\"mult_fact: {}\\n\".format(mult_fact))\n",
    "f.write(\"nalm_model: {}\\n\".format(nalm_model))\n",
    "f.write(\"seed_value: {}\\n\".format(seed_value))\n",
    "f.write(\"dropout_val: {}\\n\".format(dropout_val))\n",
    "f.write(\"n_hidden_layer: {}\\n\".format(n_hidden_layer))\n",
    "f.close()\n",
    "\n",
    "filename = \"log_perf.txt\"\n",
    "f = open(filename, \"a\")\n",
    "f.write(\"\\n{}, {}, {}, {}, {}, {}, {}, {}, True\".format(nalm_model, statstr(metric_val_ml), seed_value, int(0.9*ilim), x_test.shape[0], dropout_val, spectrum, mult_fact))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_camb = CreateCosmology(nside,lmax)\n",
    "\n",
    "n_new_x_test = 1000\n",
    "\n",
    "path_dir_data = \"data_FullSky_100_new_test\"\n",
    "if noisy_bool:\n",
    "    path_dir_data = path_dir_data + \"_noise\"\n",
    "path_dir_data = path_dir_data + \"/\"\n",
    "\n",
    "base_data_file = path_dir_data + \"data_FullSky_nside_{}_100_new_test\".format(nside)\n",
    "\n",
    "data_filename = base_data_file + \"_0.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a full sky map\n",
    "def CreateAnafastFullSky_(cl, nside, lmax, plot_results = False, noise_rms = 200):\n",
    "\n",
    "    map_ = hp.synfast(cl.T, nside, pixwin=False, verbose=False, new = True)\n",
    "    npix = 12 * nside ** 2\n",
    "    noise = np.random.randn(npix)*noise_rms\n",
    "    map_ = map_ + noise\n",
    "\n",
    "    # Anafast spectrum of this map\n",
    "    cl_ana, alm_ana = hp.anafast(map_, alm=True, lmax=lmax)\n",
    "\n",
    "    return alm_ana, cl_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_type='Linear'\n",
    "\n",
    "theshape = Shape(shape_type, lmax, np.arange(0, lmax+1))\n",
    "theshape_ = np.ones(cl_camb.shape)\n",
    "for l in range(cl_camb.shape[0]):\n",
    "    theshape_[l, :] = theshape_[l, :]*theshape[l]\n",
    "\n",
    "# store/load the generated data into/from a file\n",
    "if not os.path.isfile(data_filename):\n",
    "        for i in range(n_new_x_test//100):\n",
    "            all_alm_ana_trans, all_cl_anafast_trans = np.zeros(shape=(3, 100, nalm))*1j, np.zeros(shape=(4, 100, nl))\n",
    "            for j in range(100):\n",
    "                [alm_ana, cl_ana] = CreateAnafastFullSky_(cl_camb * theshape_, nside, lmax, noise_rms = noise_rms)              \n",
    "                if j == 0:\n",
    "                    print(i*100)\n",
    "                all_alm_ana_trans[:, j, :] = alm_ana\n",
    "                all_cl_anafast_trans[:, j, :] = cl_ana[:4, :]\n",
    "            #\"\"\"\n",
    "            if not os.path.isdir(path_dir_data):\n",
    "                os.mkdir(path_dir_data)\n",
    "            data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "            data_file = open(data_filename, \"wb\")\n",
    "            pickle.dump([all_alm_ana_trans, all_cl_anafast_trans, (cl_camb * theshape_).T], data_file)\n",
    "            data_file.close()\n",
    "            #\"\"\"\n",
    "\n",
    "all_cl_theo_new_test, all_alm_ana_new_test, all_cl_anafast_new_test = np.array([]), np.array([]), np.array([])\n",
    "for i in range(len(os.listdir(path_dir_data))):\n",
    "    data_filename = base_data_file + \"_{}.pickle\".format(i)\n",
    "    try:\n",
    "        data_file = open(data_filename, \"rb\")\n",
    "    except:\n",
    "        continue\n",
    "    [all_alm_ana_trans, all_cl_anafast_trans, cl_theo_new_test] = pickle.load(data_file)\n",
    "    if idx_cell < 3: # TT, EE or BB \n",
    "        all_alm_ana_trans, all_cl_anafast_trans, cl_theo_new_test = all_alm_ana_trans[idx_cell], all_cl_anafast_trans[idx_cell], cl_theo_new_test[idx_cell]\n",
    "    else: # We need alm of T and E\n",
    "        print(\"idx_cell >= 3 not implemented\")\n",
    "        exit()\n",
    "        all_cl_theo_binned_trans, all_alm_ana_trans, all_cl_anafast_binned_trans = all_cl_theo_binned_trans[idx_cell], all_alm_ana_trans[0], all_cl_anafast_binned_trans[idx_cell]\n",
    "        exit()\n",
    "    if i == 0:\n",
    "        all_alm_ana_new_test = all_alm_ana_trans.copy()\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_new_test = all_cl_anafast_trans.copy()\n",
    "        all_cl_anafast_trans = []\n",
    "    else:\n",
    "        all_alm_ana_new_test = np.append(all_alm_ana_new_test, all_alm_ana_trans, axis=0)\n",
    "        all_alm_ana_trans = []\n",
    "        all_cl_anafast_new_test = np.append(all_cl_anafast_new_test, all_cl_anafast_trans, axis=0)\n",
    "        all_cl_anafast_trans = []\n",
    "        #print(all_cl_anafast_new_test)\n",
    "    data_file.close()\n",
    "    if all_cl_anafast_new_test.shape[0] >= n_new_x_test:\n",
    "        break\n",
    "\n",
    "all_cl_theo_new_test = cl_theo_new_test\n",
    "\n",
    "print(all_cl_anafast_new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting l range\n",
    "all_cl_theo_new_test = all_cl_theo_new_test[new_lmin:new_lmax+1]\n",
    "all_cl_anafast_new_test = all_cl_anafast_new_test[:, new_lmin:new_lmax+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "all_alm_ana_new_test = np.stack((all_alm_ana_new_test.real/max_alm_real, all_alm_ana_new_test.imag/max_alm_imag), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_test = all_alm_ana_new_test\n",
    "new_y_test = all_cl_theo_new_test + noise_rms**2*4*np.pi/npix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network predictions\n",
    "result = model.predict(new_x_test, batch_size=128)/mult_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_result_np = np.mean(result, axis=0)\n",
    "std_result_np = np.std(result, axis=0)\n",
    "#\"\"\"\n",
    "mean_result = np.zeros(nl_used)\n",
    "mean_ana = np.zeros(nl_used)\n",
    "for i in range(n_new_x_test):\n",
    "    mean_result += result[i, :]\n",
    "    mean_ana += all_cl_anafast_new_test[i, :]\n",
    "mean_result /= n_new_x_test\n",
    "mean_ana /= n_new_x_test\n",
    "print(mean_result_np-mean_result)\n",
    "std_result = np.zeros(nl_used)\n",
    "std_ana = np.zeros(nl_used)\n",
    "for i in range(n_new_x_test):\n",
    "    std_result += (result[i, :]-mean_result)**2\n",
    "    std_ana += (all_cl_anafast_new_test[i, :]-mean_ana)**2\n",
    "std_result = np.sqrt(std_result/n_new_x_test)\n",
    "std_ana = np.sqrt(std_ana/n_new_x_test)\n",
    "#\"\"\"\n",
    "sample_variance_new_test = 2/(2*ll +1)new_y_test**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "if noisy_bool:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra + noise')\n",
    "else:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra')\n",
    "\n",
    "plt.errorbar(ll-0.2, ll * (ll + 1) / (2*np.pi) * mean_ana, yerr = ll * (ll + 1) / (2*np.pi) * std_ana, fmt='.', color=\"orange\", label='Mean Anafast')\n",
    "plt.errorbar(ll, ll * (ll + 1) / (2*np.pi) * mean_result, yerr = ll * (ll + 1) / (2*np.pi) * std_result, fmt='m.', label='Mean ML')\n",
    "plt.errorbar(ll+0.2, ll * (ll + 1) / (2*np.pi) * new_y_test[:], yerr = ll * (ll + 1) / (2*np.pi) * np.sqrt(sample_variance_new_test)[:], fmt='b.', label='Sample variance')\n",
    "\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "plt.ylabel(text)\n",
    "plt.title(spectrum)\n",
    "plt.legend()\n",
    "figname = 'fig_prediction_mean.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "if noisy_bool:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra + noise')\n",
    "else:\n",
    "    plt.plot(ll, ll * (ll + 1) / (2*np.pi) * new_y_test[:], label='Binned input spectra')\n",
    "\n",
    "plt.errorbar(ll, ll * (ll + 1) / (2*np.pi) * mean_result, yerr = ll * (ll + 1) / (2*np.pi) * std_result, fmt='m.', label='Mean ML')\n",
    "\n",
    "plt.xlabel(r\"$\\ell$\")\n",
    "text = r\"$D_{\\ell}^{\" + spectrum + r\"}$\"\n",
    "plt.ylabel(text)\n",
    "plt.title(spectrum)\n",
    "plt.legend()\n",
    "figname = 'fig_prediction_mean_only_ML.png'\n",
    "dest = os.path.join(path, figname)\n",
    "plt.savefig(dest, bbox_inches='tight')  # write image to file\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
